{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee515b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', frame) \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13080852",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "\n",
    "\n",
    "DISTANCE_TO_OBJECT = 1000  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "face_height_default = 300 #gaze[\"face\"][\"height\"]\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "#no_circle = 1\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    #image_height, image_width = frame.shape[:2]\n",
    "    \n",
    "    #cv2.resizeWindow('Window', image_width*2, image_height*2)\n",
    "    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / face_height_default\n",
    "\n",
    "    dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "    \n",
    "\n",
    "    gaze_point = int(image_width / 2 + dx), int(image_height / 2 + dy + 200)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-5:]\n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    #cv2.circle(frame, gaze_point, 25, (0, 0, 255), -1)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('w'):\n",
    "        \n",
    "#         no_circle = no_circle*(-1)\n",
    "        \n",
    "#     if not no_circle < 1:\n",
    "    \n",
    "#         cv2.circle(frame, (image_width//2, image_height//2), 25, (0, 0, 255), -1)\n",
    "    \n",
    "    cv2.circle(frame, tuple(avg_gaze_point), 25, (0, 0, 255), -1)\n",
    "    cv2.circle(frame, (image_width//2, image_height//2), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(frame, (x_gaze, y_gaze), 25, (0, 255, 0), -1)\n",
    "\n",
    "#     label = f'pitch {results.pitch[0]} yaw {results.yaw[0]}'\n",
    "    \n",
    "#     cv2.putText(frame , label, (100, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', frame) \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d95cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(face_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc787784",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.bboxes[0])\n",
    "print((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "print((results.bboxes[0][1]+results.bboxes[0][3])//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34241492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('pitch', results.pitch[0], 'yaw', results.yaw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5230e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb92c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze_point_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze_point_array[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4de943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaze_point_array[-1:-0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = gaze_point_array[-4:-3][0][0]\n",
    "x_4 = gaze_point_array[-1:-0][0][0]\n",
    "\n",
    "y_1 = gaze_point_array[-4:-3][0][1]\n",
    "y_4 = gaze_point_array[-1:-0][0][1]\n",
    "\n",
    "x_med = (x_1 + x_4)//2\n",
    "y_med = (y_1 + y_4)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb7a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from screeninfo import get_monitors\n",
    "for monitor in get_monitors():\n",
    "    print(str(monitor.width) + 'x' + str(monitor.height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install screeninfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0712926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_monitors()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_monitors()[0].width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------can be reversed\n",
    "\n",
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "\n",
    "\n",
    "DISTANCE_TO_OBJECT = 1000  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "face_height_default = 300 #gaze[\"face\"][\"height\"]\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "\n",
    "# Open the first video capture object (replace 'Foreground.mp4' with your foreground video file)\n",
    "cap1 = cv2.VideoCapture('foreground.mp4')\n",
    "\n",
    "# Get the width and height of the foreground video frames\n",
    "# width_fg = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height_fg = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Open the first video capture object (replace 'Foreground.mp4' with your foreground video file)\n",
    "cap2 = cv2.VideoCapture('background.mp4')\n",
    "\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "displacements = []\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "avg_displacement = 0\n",
    "#no_circle = 1\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    #image_height, image_width = frame.shape[:2]\n",
    "    \n",
    "    #cv2.resizeWindow('Window', image_width*2, image_height*2)\n",
    "    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / face_height_default\n",
    "\n",
    "    dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "    \n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-10:]\n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-10:]\n",
    "    \n",
    "\n",
    "    \n",
    "    displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "\n",
    "    displacements.append(displacement)\n",
    "\n",
    "    displacements = displacements[-10:]\n",
    "    \n",
    "\n",
    "    avg_displacement = np.mean(displacements, axis=0).astype(int)\n",
    "#-----------------------------------    \n",
    "    opacity = 25*int((displacement_max-4*avg_displacement)/(4*displacement+1))\n",
    "\n",
    "    tail = 2\n",
    "\n",
    "    avg_gaze_points = avg_gaze_points[-tail:]\n",
    "#--------------------------------------\n",
    "    # Read a frame from the foreground video\n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "    circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    # Draw a black circle at the cursor's position on the mask\n",
    "    #cv2.circle(circle_mask, tuple(avg_gaze_point), 250, (255, 255, 255), -1)\n",
    "    opacity_incr = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(avg_gaze_points)):\n",
    "        \n",
    "        avg_gaze_point = avg_gaze_points[i]\n",
    "        \n",
    "        radius = 250\n",
    "        \n",
    "        cv2.circle(circle_mask, tuple(avg_gaze_point), radius, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "        opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    #mask = cv2.GaussianBlur(mask, (25, 25), 0)\n",
    "    \n",
    "#     fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "#     _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "#     binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "     \n",
    "#     r_mask = cv2.bitwise_and(binary_mask, circle_mask)\n",
    "    \n",
    "#     # Define the parameters for brightness and contrast adjustment\n",
    "#     alpha = 5  # Contrast control (1.0 means no change)\n",
    "#     beta = 20    # Brightness control (0 means no change)\n",
    "\n",
    "#     # Apply the brightness and contrast adjustment\n",
    "#     r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    \n",
    "#     \n",
    "\n",
    "    r_mask = circle_mask \n",
    "    \n",
    "#     r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    mask_normalized = (r_mask/255).astype(float)\n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(mask_normalized, frame2_n) + cv2.multiply(1- mask_normalized, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('w'):\n",
    "        \n",
    "#         no_circle = no_circle*(-1)\n",
    "        \n",
    "#     if not no_circle < 1:\n",
    "    \n",
    "#         cv2.circle(frame, (image_width//2, image_height//2), 25, (0, 0, 255), -1)\n",
    "    \n",
    "    #cv2.circle(frame, tuple(avg_gaze_point), 25, (0, 0, 255), -1)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(result_frame, \"Optimal distance\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(result_frame, (image_width//2, image_height//2), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(result_frame, (x_gaze, y_gaze), 25, (0, 255, 0), -1)\n",
    "\n",
    "#     label = f'pitch {results.pitch[0]} yaw {results.yaw[0]}'\n",
    "    \n",
    "#     cv2.putText(frame , label, (100, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40290df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7074c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba9613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89d607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20942389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(face_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3866cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "mask_normalized = (circle_mask/125).astype(int)\n",
    "\n",
    "var = r_mask/127.5\n",
    "\n",
    "\n",
    "# Assuming circle_mask contains your image data\n",
    "# If it's a single-channel image, convert it to RGB for display\n",
    "if circle_mask.ndim == 2:\n",
    "    circle_mask_display = cv2.cvtColor(var, cv2.COLOR_GRAY2RGB)\n",
    "else:\n",
    "    circle_mask_display = var.copy()\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(circle_mask_display)\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df25738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a71fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e28b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94897cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7318819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Not using CUDA\")\n",
    "\n",
    "\n",
    "DISTANCE_TO_OBJECT = 1000  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "face_height_default = 300 #gaze[\"face\"][\"height\"]\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open the first video capture object \n",
    "cap1 = cv2.VideoCapture('foreground.mp4')\n",
    "\n",
    "# Get the width and height of the foreground video frames\n",
    "# width_fg = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height_fg = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Open the first video capture object\n",
    "cap2 = cv2.VideoCapture('background2.mp4')\n",
    "\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "contour_masks = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "threshold_distances = []\n",
    "\n",
    "contourss = []\n",
    "\n",
    "displacement = 0\n",
    "\n",
    "threshold_distance_avg = 0\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "#no_circle = 1\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    #image_height, image_width = frame.shape[:2]\n",
    "    \n",
    "    #cv2.resizeWindow('Window', image_width*2, image_height*2)\n",
    "    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / face_height_default\n",
    "\n",
    "    dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    \n",
    "    #dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])/length_per_pixel\n",
    "    \n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "    \n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-5:]\n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-2:]\n",
    "    \n",
    "    if len(avg_gaze_points)>1:\n",
    "    \n",
    "        displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "    \n",
    "        #displacement = int(displacement)\n",
    "#-----------------------------------    \n",
    "#     opacity = 255\n",
    "\n",
    "#     tail = 10\n",
    "\n",
    "#     avg_gaze_points = avg_gaze_points[-tail:]\n",
    "#--------------------------------------\n",
    "    # Read a frame from the foreground video\n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "#     circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    # Draw a black circle at the cursor's position on the mask\n",
    "    #cv2.circle(circle_mask, tuple(avg_gaze_point), 250, (255, 255, 255), -1)\n",
    "#     opacity_incr = 0\n",
    "    \n",
    "#     for avg_gaze_point in avg_gaze_points:\n",
    "#         cv2.circle(circle_mask, tuple(avg_gaze_point), 250, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "#         opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    #mask = cv2.GaussianBlur(mask, (25, 25), 0)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Step 4: Create a mask for contours intersecting with the circle\n",
    "    contour_mask = np.zeros_like(frame1)\n",
    "\n",
    "    # Set a threshold distance to determine which contours to keep\n",
    "    threshold_distance = 200 + int(displacement_max/(displacement+0.1))   # Adjust as needed\n",
    "    \n",
    "    threshold_distances.append(threshold_distance)\n",
    "    \n",
    "    threshold_distances = threshold_distances[-10:]\n",
    "    \n",
    "    threshold_distance_avg= np.mean(threshold_distances).astype(int)\n",
    "\n",
    "    contourss.append(contours)\n",
    "    \n",
    "    contourss = contourss[-10:]\n",
    "    \n",
    "    opacity = 255\n",
    "    \n",
    "    op = 0\n",
    "    \n",
    "    for i in range(len(contourss)):\n",
    "        \n",
    "        contours = contourss[i]\n",
    "\n",
    "        # Loop through each contour and find its center\n",
    "        for contour in contours:\n",
    "\n",
    "            # Simplify the contour\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            simplified_contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "            # Calculate the moments of the contour\n",
    "            moments = cv2.moments(contour)\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if moments['m00'] != 0:\n",
    "                # Calculate the centroid coordinates\n",
    "                cx = int(moments['m10'] / moments['m00'])\n",
    "                cy = int(moments['m01'] / moments['m00'])\n",
    "\n",
    "                # Calculate the distance between the centroid and avg_gaze_point\n",
    "                distance_to_gaze = np.sqrt((cx - avg_gaze_point[0])**2 + (cy - avg_gaze_point[1])**2)\n",
    "\n",
    "                # Check if the contour is close to avg_gaze_point\n",
    "                if distance_to_gaze < threshold_distances[i]:\n",
    "                    \n",
    "                    # Draw a circle at the centroid\n",
    "                    #cv2.circle(contour_mask, (cx, cy), 5, (255, 255, 0), -1)  # Green circle\n",
    "                    cv2.drawContours(contour_mask, [contour], -1, (op, op, op), thickness=cv2.FILLED)\n",
    "                    cv2.drawContours(contour_mask, [contour], -1, (op, op, op), thickness=1)\n",
    "                    #cv2.fillPoly(contour_mask, [contour], color=(255, 255, 255))\n",
    "                    \n",
    "            if i <  int(len(contourss)/2):\n",
    "\n",
    "                op += int(2*opacity/len(contourss))\n",
    "            else:\n",
    "\n",
    "                op -= int(2*opacity/len(contourss))\n",
    "\n",
    "    \n",
    "    \n",
    "    contour_masks.append(contour_mask)\n",
    "    \n",
    "    opacity = 255\n",
    "\n",
    "    tail = 5\n",
    "\n",
    "    contour_masks = contour_masks[-tail:]\n",
    "    \n",
    "    contour_mask_template = np.zeros_like(frame1)\n",
    "    \n",
    "    opacity_incr = 0\n",
    "    \n",
    "    for contour_mask in contour_masks:\n",
    "        contour_mask_template = cv2.addWeighted(contour_mask_template, 1, contour_mask, opacity_incr, 1)\n",
    "        \n",
    "        opacity_incr += (opacity/len(contour_masks))/255\n",
    "    \n",
    "    \n",
    "    r_mask = contour_mask_template\n",
    "    \n",
    "    #r_mask = contour_mask\n",
    "    \n",
    "    \n",
    "    #r_mask = cv2.bitwise_and(binary_mask, circle_mask)\n",
    "    \n",
    "    # Define the parameters for brightness and contrast adjustment\n",
    "    alpha = 15  # Contrast control (1.0 means no change)\n",
    "    beta = int(threshold_distance/20)    # Brightness control (0 means no change)\n",
    "\n",
    "    \n",
    "    \n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    \n",
    "    # Apply the brightness and contrast adjustment\n",
    "    r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    r_mask = (r_mask/255).astype(float)\n",
    "    \n",
    "    #mask_normalized = r_mask\n",
    "    \n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(r_mask, frame2_n) + cv2.multiply(1- r_mask, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('w'):\n",
    "        \n",
    "#         no_circle = no_circle*(-1)\n",
    "        \n",
    "#     if not no_circle < 1:\n",
    "    \n",
    "#         cv2.circle(frame, (image_width//2, image_height//2), 25, (0, 0, 255), -1)\n",
    "    \n",
    "    #cv2.circle(frame, tuple(avg_gaze_point), 25, (0, 0, 255), -1)\n",
    "    cv2.putText(r_mask, f\"Displacement {int(displacement)}\", (500, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Threshold {threshold_distance}\", (1000, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(r_mask, \"Optimal distance\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(r_mask, (image_width//2, image_height//2), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(r_mask, (x_gaze, y_gaze), 25, (0, 255, 0), -1)\n",
    "\n",
    "#     label = f'pitch {results.pitch[0]} yaw {results.yaw[0]}'\n",
    "    \n",
    "#     cv2.putText(frame , label, (100, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1324ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(screen_width**2 + get_monitors()[0].height**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d14a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contours[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Not using CUDA\")\n",
    "\n",
    "\n",
    "DISTANCE_TO_OBJECT = 1000  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "face_height_default = 300 #gaze[\"face\"][\"height\"]\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open the first video capture object \n",
    "cap1 = cv2.VideoCapture('foreground.mp4')\n",
    "\n",
    "# Get the width and height of the foreground video frames\n",
    "# width_fg = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height_fg = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Open the first video capture object\n",
    "cap2 = cv2.VideoCapture('background2.mp4')\n",
    "\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "contour_masks = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "threshold_distances = []\n",
    "\n",
    "contourss = []\n",
    "\n",
    "displacement = 0\n",
    "\n",
    "displacements = []\n",
    "\n",
    "avg_displacement = 0\n",
    "\n",
    "threshold_distance_avg = 0\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "#no_circle = 1\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    #image_height, image_width = frame.shape[:2]\n",
    "    \n",
    "    #cv2.resizeWindow('Window', image_width*2, image_height*2)\n",
    "    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / face_height_default\n",
    "\n",
    "    dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    \n",
    "    #dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])/length_per_pixel\n",
    "    \n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "    \n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-5:]\n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-10:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "\n",
    "    displacements.append(displacement)\n",
    "\n",
    "    displacements = displacements[-10:]\n",
    "\n",
    "    avg_displacement = np.mean(displacements, axis=0).astype(int)\n",
    "        \n",
    "        \n",
    "        #displacement = int(displacement)\n",
    "#-----------------------------------    \n",
    "#     opacity = 255\n",
    "\n",
    "#     tail = 10\n",
    "\n",
    "#     avg_gaze_points = avg_gaze_points[-tail:]\n",
    "#--------------------------------------\n",
    "    # Read a frame from the foreground video\n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "#     circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    # Draw a black circle at the cursor's position on the mask\n",
    "    #cv2.circle(circle_mask, tuple(avg_gaze_point), 250, (255, 255, 255), -1)\n",
    "#     opacity_incr = 0\n",
    "    \n",
    "#     for avg_gaze_point in avg_gaze_points:\n",
    "#         cv2.circle(circle_mask, tuple(avg_gaze_point), 250, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "#         opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    #mask = cv2.GaussianBlur(mask, (25, 25), 0)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Step 4: Create a mask for contours intersecting with the circle\n",
    "    contour_mask = np.zeros_like(frame1)\n",
    "\n",
    "    # Set a threshold distance to determine which contours to keep\n",
    "    threshold_distance = 200 + int(displacement_max/(displacement+0.1))   # Adjust as needed\n",
    "    \n",
    "    threshold_distances.append(threshold_distance)\n",
    "    \n",
    "    threshold_distances = threshold_distances[-10:]\n",
    "    \n",
    "    threshold_distance_avg= np.mean(threshold_distances).astype(int)\n",
    "\n",
    "    contourss.append(contours)\n",
    "    \n",
    "    contourss = contourss[-10:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    op = 0\n",
    "    \n",
    "    for i in range(len(contourss)):\n",
    "        \n",
    "        contours = contourss[i]\n",
    "        \n",
    "        opacity = 25*int((displacement_max-4*avg_displacement)/(displacements[i]+1))\n",
    "\n",
    "        # Loop through each contour and find its center\n",
    "        for contour in contours:\n",
    "\n",
    "            # Simplify the contour\n",
    "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "            simplified_contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "            # Calculate the moments of the contour\n",
    "            moments = cv2.moments(contour)\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if moments['m00'] != 0:\n",
    "                # Calculate the centroid coordinates\n",
    "                cx = int(moments['m10'] / moments['m00'])\n",
    "                cy = int(moments['m01'] / moments['m00'])\n",
    "\n",
    "                # Calculate the distance between the centroid and avg_gaze_point\n",
    "                distance_to_gaze = np.sqrt((cx - avg_gaze_points[i][0])**2 + (cy - avg_gaze_points[i][1])**2)\n",
    "\n",
    "                # Check if the contour is close to avg_gaze_point\n",
    "                if distance_to_gaze <  threshold_distances[i]:\n",
    "                    \n",
    "                    # Draw a circle at the centroid\n",
    "                    #cv2.circle(contour_mask, (cx, cy), 5, (255, 255, 0), -1)  # Green circle\n",
    "                    cv2.drawContours(contour_mask, [contour], -1, (op, op, op), thickness=cv2.FILLED)\n",
    "                    cv2.drawContours(contour_mask, [contour], -1, (op, op, op), thickness=1)\n",
    "                    #cv2.fillPoly(contour_mask, [contour], color=(255, 255, 255))\n",
    "                    \n",
    "\n",
    "        op += int(opacity/len(contourss))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    contour_masks.append(contour_mask)\n",
    "    \n",
    "    opacity = 255\n",
    "\n",
    "    tail = 5\n",
    "\n",
    "    contour_masks = contour_masks[-tail:]\n",
    "    \n",
    "    contour_mask_template = np.zeros_like(frame1)\n",
    "    \n",
    "    opacity_incr = 0\n",
    "    \n",
    "    for contour_mask in contour_masks:\n",
    "        contour_mask_template = cv2.addWeighted(contour_mask_template, 1, contour_mask, opacity_incr, 1)\n",
    "        \n",
    "        opacity_incr += (opacity/len(contour_masks))/255\n",
    "    \n",
    "    \n",
    "    r_mask = contour_mask_template\n",
    "    \n",
    "    #r_mask = contour_mask\n",
    "    \n",
    "    \n",
    "    #r_mask = cv2.bitwise_and(binary_mask, circle_mask)\n",
    "    \n",
    "    # Define the parameters for brightness and contrast adjustment\n",
    "    alpha = 15  # Contrast control (1.0 means no change)\n",
    "    beta = int(threshold_distance/20)    # Brightness control (0 means no change)\n",
    "\n",
    "    \n",
    "    \n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    \n",
    "    # Apply the brightness and contrast adjustment\n",
    "    r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    r_mask = (r_mask/255).astype(float)\n",
    "    \n",
    "    #mask_normalized = r_mask\n",
    "    \n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(r_mask, frame2_n) + cv2.multiply(1- r_mask, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('w'):\n",
    "        \n",
    "#         no_circle = no_circle*(-1)\n",
    "        \n",
    "#     if not no_circle < 1:\n",
    "    \n",
    "#         cv2.circle(frame, (image_width//2, image_height//2), 25, (0, 0, 255), -1)\n",
    "    \n",
    "    #cv2.circle(frame, tuple(avg_gaze_point), 25, (0, 0, 255), -1)\n",
    "    cv2.putText(r_mask, f\"Displacement {int(displacement)}\", (500, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Threshold {threshold_distance}\", (1000, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(r_mask, \"Optimal distance\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(r_mask, (image_width//2, image_height//2), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(r_mask, (x_gaze, y_gaze), 25, (0, 255, 0), -1)\n",
    "\n",
    "#     label = f'pitch {results.pitch[0]} yaw {results.yaw[0]}'\n",
    "    \n",
    "#     cv2.putText(frame , label, (100, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------Don't touch--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------Don't touch--------------------------------------\n",
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Not using CUDA\")\n",
    "\n",
    "DISTANCE_TO_OBJECT = 500  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "# Open the first video capture object \n",
    "cap1 = cv2.VideoCapture('foreground.mp4')\n",
    "\n",
    "# Open the first video capture object\n",
    "cap2 = cv2.VideoCapture('background2.mp4')\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "displacement = 0\n",
    "\n",
    "avg_displacement = 0\n",
    "\n",
    "displacements = []\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / (1.5*face_height)\n",
    "\n",
    "    dx = -2*DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    \n",
    "    #dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])/length_per_pixel\n",
    "    \n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -2*DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-10:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-2:] #<----------------tail\n",
    "    \n",
    "\n",
    "\n",
    "    displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "\n",
    "    displacements.append(displacement)\n",
    "\n",
    "    displacements = displacements[-10:]\n",
    "\n",
    "    avg_displacement = np.mean(displacements, axis=0).astype(int)\n",
    "    \n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Read a frame from the foreground video\n",
    "    \n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "    circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    opacity_incr = 0\n",
    "\n",
    "    for i in range(len(avg_gaze_points)):\n",
    "        \n",
    "        radius = 0\n",
    "        \n",
    "        opacity = 0 + 15*int((displacement_max-4*avg_displacement)/(3*displacements[i]+1))\n",
    "        \n",
    "        avg_gaze_point = avg_gaze_points[i]\n",
    "        \n",
    "        r= image_height - 2*int(avg_displacement)\n",
    "        \n",
    "        if r> 0:\n",
    "            \n",
    "            radius = r\n",
    "\n",
    "        cv2.circle(circle_mask, tuple(avg_gaze_point), radius, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "       \n",
    "        opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    r_mask = cv2.bitwise_and(binary_mask,circle_mask)\n",
    "\n",
    "    # Define the parameters for brightness and contrast adjustment\n",
    "    alpha = 15  # Contrast control (1.0 means no change)\n",
    "\n",
    "    \n",
    "    d = displacement_max - 20*avg_displacement\n",
    "     \n",
    "    if d > 0:\n",
    "        beta = 20 + (d/250)**3 # Brightness control (0 means no change)\n",
    "    else:\n",
    "        beta = 20\n",
    "\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    \n",
    "    # Apply the brightness and contrast adjustment\n",
    "    r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    r_mask = (r_mask/255).astype(float) \n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(r_mask, frame2_n) + cv2.multiply(1- r_mask, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    cv2.putText(r_mask, f\"Displacement {int(displacement)}\", (500, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Radius {radius}\", (1000, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Face height {face_height}\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(r_mask, \"Optimal distance\", (50, 120), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(r_mask, (image_width//2 - 225, image_height//2-50), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(r_mask, (x_gaze - 225 , y_gaze-50), 25, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242786f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------touch--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------touch--------------------------------------\n",
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Not using CUDA\")\n",
    "    \n",
    "filename1 = 'floatsam_front.mp4'\n",
    "filename2 = 'floatsam_back.mp4'\n",
    "folder_path = filename1 + filename2\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "else:\n",
    "    if not os.path.exists(f'{folder_path}/result'):\n",
    "        os.makedirs(f'{folder_path}/result')\n",
    "    if not os.path.exists(f'{folder_path}/mask'):\n",
    "        os.makedirs(f'{folder_path}/mask')\n",
    "    if not os.path.exists(f'{folder_path}/camera'):\n",
    "        os.makedirs(f'{folder_path}/camera')\n",
    "\n",
    "DISTANCE_TO_OBJECT = 500  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "image_min = min(image_height, image_width)\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "# Open the first video capture object \n",
    "cap1 = cv2.VideoCapture(filename1)\n",
    "\n",
    "fps = 10\n",
    "\n",
    "# Open the first video capture object\n",
    "cap2 = cv2.VideoCapture(filename2)\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "# out_result = cv2.VideoWriter(f'{filename1}_result.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "# out_mask = cv2.VideoWriter(f'{filename1}_mask.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "# out_camera = cv2.VideoWriter(f'{filename1}_camera.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "count = 0\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "displacement = 0\n",
    "\n",
    "avg_displacement = 0\n",
    "\n",
    "displacements = []\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / (1.5*face_height)\n",
    "\n",
    "    dx = -2*DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    \n",
    "    #dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])/length_per_pixel\n",
    "    \n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -2*DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-10:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-2:] #<----------------tail\n",
    "    \n",
    "\n",
    "\n",
    "    displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "\n",
    "    displacements.append(displacement)\n",
    "\n",
    "    displacements = displacements[-10:]\n",
    "\n",
    "    avg_displacement = np.mean(displacements, axis=0).astype(int)\n",
    "    \n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Read a frame from the foreground video\n",
    "    \n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "    circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    opacity_incr = 0\n",
    "\n",
    "    for i in range(len(avg_gaze_points)):\n",
    "        \n",
    "        radius = 0\n",
    "        \n",
    "        opacity = 0 + 15*int((displacement_max-4*avg_displacement)/(3*displacements[i]+1))\n",
    "        \n",
    "        avg_gaze_point = avg_gaze_points[i]\n",
    "        \n",
    "        r= image_height - 3*int(avg_displacement)\n",
    "        \n",
    "        if r> 0:\n",
    "            \n",
    "            radius = r\n",
    "\n",
    "        cv2.circle(circle_mask, tuple(avg_gaze_point), radius, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "       \n",
    "        opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    r_mask = cv2.bitwise_and(binary_mask,circle_mask)\n",
    "\n",
    "    # Define the parameters for brightness and contrast adjustment\n",
    "    alpha = 15  # Contrast control (1.0 means no change)\n",
    "\n",
    "    \n",
    "    d = displacement_max - 20*avg_displacement\n",
    "     \n",
    "    if d > 0:\n",
    "        beta = 20 + (d/250)**3 # Brightness control (0 means no change)\n",
    "    else:\n",
    "        beta = 20\n",
    "\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    \n",
    "    # Apply the brightness and contrast adjustment\n",
    "    r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    r_mask = (r_mask/255).astype(float) \n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(r_mask, frame2_n) + cv2.multiply(1- r_mask, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    cv2.putText(r_mask, f\"Displacement {int(displacement)}\", (500, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Radius {radius}\", (1000, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Face height {face_height}\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(r_mask, \"Optimal distance\", (50, 120), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(r_mask, (image_width//2 - 225, image_height//2-50), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(r_mask, (x_gaze - 225 , y_gaze-50), 25, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "    cv2.imshow('Camera', frame)\n",
    "    \n",
    "    \n",
    "    result_frame_8bit = cv2.normalize(result_frame, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    r_mask_8bit = (r_mask*255).astype(int)\n",
    "    \n",
    "    cv2.imwrite(f'{folder_path}/result/result_frame{count:05d}.jpg', result_frame_8bit)\n",
    "    cv2.imwrite(f'{folder_path}/mask/mask_frame{count:05d}.jpg', r_mask_8bit)\n",
    "    cv2.imwrite(f'{folder_path}/camera/camera_frame{count:05d}.jpg', frame)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7599974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2663403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
