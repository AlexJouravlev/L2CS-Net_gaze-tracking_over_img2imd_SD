{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242786f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "from l2cs import Pipeline, render\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Not using CUDA\")\n",
    "    \n",
    "filename1 = 'foreground.mp4'\n",
    "filename2 = 'background2.mp4'\n",
    "folder_path = filename1 + '_' + filename2\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "else:\n",
    "    if not os.path.exists(f'{folder_path}/result'):\n",
    "        os.makedirs(f'{folder_path}/result')\n",
    "    if not os.path.exists(f'{folder_path}/mask'):\n",
    "        os.makedirs(f'{folder_path}/mask')\n",
    "    if not os.path.exists(f'{folder_path}/camera'):\n",
    "        os.makedirs(f'{folder_path}/camera')\n",
    "\n",
    "DISTANCE_TO_OBJECT = 500  # mm\n",
    "HEIGHT_OF_HUMAN_FACE = 250  # mm\n",
    "\n",
    "gaze_pipeline = Pipeline( weights= 'models/L2CSNet_gaze360.pkl', arch='ResNet50', device=torch.device('cuda')) # or 'cuda'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "image_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "image_min = min(image_height, image_width)\n",
    "   \n",
    "screen_width = int(get_monitors()[0].height*image_width/image_height)\n",
    "\n",
    "# Create a window with an initial size\n",
    "cv2.namedWindow('Window', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Window', screen_width, get_monitors()[0].height)\n",
    "\n",
    "# Open the first video capture object \n",
    "cap1 = cv2.VideoCapture(filename1)\n",
    "\n",
    "fps = 10\n",
    "\n",
    "# Open the first video capture object\n",
    "cap2 = cv2.VideoCapture(filename2)\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "# out_result = cv2.VideoWriter(f'{filename1}_result.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "# out_mask = cv2.VideoWriter(f'{filename1}_mask.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "# out_camera = cv2.VideoWriter(f'{filename1}_camera.mp4', fourcc, fps, (screen_width, get_monitors()[0].height))\n",
    "\n",
    "x, y, width, height = 0, 0, screen_width, get_monitors()[0].height  # Adjust these values according to your requirements\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "count = 0\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "avg_gaze_points = []\n",
    "\n",
    "displacement = 0\n",
    "\n",
    "avg_displacement = 0\n",
    "\n",
    "displacements = []\n",
    "\n",
    "displacement_max = np.sqrt(screen_width**2 + get_monitors()[0].height**2)\n",
    "\n",
    "while(True): \n",
    "\n",
    "    _, frame = cap.read()    \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Process frame and visualize\n",
    "    results = gaze_pipeline.step(frame)\n",
    "    frame = render(frame, results)\n",
    "    \n",
    "    face_height = int(results.bboxes[0][3]-results.bboxes[0][1])\n",
    "    \n",
    "    length_per_pixel = HEIGHT_OF_HUMAN_FACE / (1.5*face_height)\n",
    "\n",
    "    dx = -2*DISTANCE_TO_OBJECT * np.tan(results.pitch[0])*image_width/((length_per_pixel)*image_height)\n",
    "    \n",
    "    #dx = -DISTANCE_TO_OBJECT * np.tan(results.pitch[0])/length_per_pixel\n",
    "    \n",
    "    # 100000000 is used to denote out of bounds\n",
    "    dx = dx if not np.isnan(dx) else 100000000\n",
    "    dy = -2*DISTANCE_TO_OBJECT * np.arccos(results.pitch[0])* np.tan(results.yaw[0]) / length_per_pixel\n",
    "    dy = dy if not np.isnan(dy) else 100000000\n",
    "    \n",
    "    x_gaze = int((results.bboxes[0][0]+results.bboxes[0][2])//2)\n",
    "    y_gaze = int((results.bboxes[0][1]+results.bboxes[0][3])//2)\n",
    "\n",
    "    gaze_point = int((image_width / 2 + dx)*screen_width/image_width), int((image_height / 2 + dy + 200)*get_monitors()[0].height/image_height)\n",
    "    \n",
    "    gaze_points.append(gaze_point)\n",
    "    \n",
    "    gaze_points = gaze_points[-10:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    avg_gaze_point = np.mean(gaze_points, axis=0).astype(int)\n",
    "    \n",
    "    avg_gaze_points.append(avg_gaze_point)\n",
    "    \n",
    "    avg_gaze_points = avg_gaze_points[-2:] #<----------------tail\n",
    "    \n",
    "\n",
    "\n",
    "    displacement = np.sqrt((avg_gaze_points[0][0] - avg_gaze_points[-1][0])**2 + (avg_gaze_points[0][1] - avg_gaze_points[-1][1])**2)\n",
    "\n",
    "    displacements.append(displacement)\n",
    "\n",
    "    displacements = displacements[-10:]\n",
    "\n",
    "    avg_displacement = np.mean(displacements, axis=0).astype(int)\n",
    "    \n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Read a frame from the foreground video\n",
    "    \n",
    "    ret1, frame1 = cap1.read()\n",
    "    \n",
    "    frame1 = frame1[y:y+height, x:x+width]\n",
    "    \n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # Create a black mask with the same size as the frame\n",
    "    circle_mask = np.zeros_like(frame1)\n",
    "\n",
    "    opacity_incr = 0\n",
    "\n",
    "    for i in range(len(avg_gaze_points)):\n",
    "        \n",
    "        radius = 0\n",
    "        \n",
    "        opacity = 0 + 15*int((displacement_max-4*avg_displacement)/(3*displacements[i]+1))\n",
    "        \n",
    "        avg_gaze_point = avg_gaze_points[i]\n",
    "        \n",
    "        r= image_height - 3*int(avg_displacement)\n",
    "        \n",
    "        if r> 0:\n",
    "            \n",
    "            radius = r\n",
    "\n",
    "        cv2.circle(circle_mask, tuple(avg_gaze_point), radius, (opacity_incr, opacity_incr, opacity_incr), -1)\n",
    "       \n",
    "        opacity_incr += opacity/len(avg_gaze_points)\n",
    "    \n",
    "    fg_mask = bg_subtractor.apply(frame1)\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(fg_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    r_mask = cv2.bitwise_and(binary_mask,circle_mask)\n",
    "\n",
    "    # Define the parameters for brightness and contrast adjustment\n",
    "    alpha = 15  # Contrast control (1.0 means no change)\n",
    "\n",
    "    \n",
    "    d = displacement_max - 20*avg_displacement\n",
    "     \n",
    "    if d > 0:\n",
    "        beta = 20 + (d/250)**3 # Brightness control (0 means no change)\n",
    "    else:\n",
    "        beta = 20\n",
    "\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    \n",
    "    # Apply the brightness and contrast adjustment\n",
    "    r_mask = cv2.convertScaleAbs(r_mask, alpha=alpha, beta=beta)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "    r_mask = cv2.GaussianBlur(r_mask, (25, 25), 200)\n",
    "#-----------------------------------  \n",
    "    # Read a frame from the background video\n",
    "    ret2, frame2 = cap2.read()\n",
    "    \n",
    "    frame2 = frame2[y:y+height, x:x+width]\n",
    "\n",
    "    if not ret2:\n",
    "        break\n",
    "\n",
    "    r_mask = (r_mask/255).astype(float) \n",
    "    frame2_n = (frame2/255).astype(float)\n",
    "    frame1_n = (frame1/255).astype(float)\n",
    "\n",
    "    result_frame = cv2.multiply(r_mask, frame2_n) + cv2.multiply(1- r_mask, frame1_n)\n",
    "\n",
    "    cv2.circle(r_mask, gaze_point, 25, (0, 0, 255), -1)\n",
    "    cv2.putText(r_mask, f\"Displacement {int(displacement)}\", (500, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Radius {radius}\", (1000, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    cv2.putText(r_mask, f\"Face height {face_height}\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    if 200<face_height<220: #190-205\n",
    "        cv2.putText(r_mask, \"Optimal distance\", (50, 120), cv2.FONT_HERSHEY_PLAIN, 3, (255, face_height, 0), 3)\n",
    "    \n",
    "    cv2.circle(r_mask, (image_width//2 - 225, image_height//2-50), 25, (0, 65, 255), -1)\n",
    "    cv2.circle(r_mask, (x_gaze - 225 , y_gaze-50), 25, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Window', result_frame)\n",
    "    cv2.imshow('Mask', r_mask)\n",
    "    cv2.imshow('Camera', frame)\n",
    "    \n",
    "    \n",
    "    result_frame_8bit = cv2.normalize(result_frame, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    r_mask_8bit = (r_mask*255).astype(int)\n",
    "    \n",
    "    cv2.imwrite(f'{folder_path}/result/result_frame{count:05d}.jpg', result_frame_8bit)\n",
    "    cv2.imwrite(f'{folder_path}/mask/mask_frame{count:05d}.jpg', r_mask_8bit)\n",
    "    cv2.imwrite(f'{folder_path}/camera/camera_frame{count:05d}.jpg', frame)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
